# -*- coding: utf-8 -*-
"""lab1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FjyF-BR_8TJuCGqyDiDoPmn8QN6rz1_1
"""

import pandas as pd
print("\t--- Aneesh Lab-1 ---")

# Step 1: Load the dataset
# Corrected the filename to 'employee_data.csv' assuming it exists
df = pd.read_csv('employee_data.csv')
print("\nInitial Data:\n", df.head())

# Step 2: Handle missing values
# Fill missing 'Age' with the mean age and 'Salary' with the mean salary
df = df.fillna({
    'Age': df['Age'].mean(),
    'Salary': df['Salary'].mean()
})

# Step 3: Standardize department names
df['Department'] = df['Department'].replace({
    'Human Resources': 'HR',
    'H.R.': 'HR',
    'hr': 'HR'
})

# Step 4: Remove duplicate records based on 'ID'
df.drop_duplicates(subset='ID', keep='first', inplace=True)

print("\nCleaned Data:\n", df.head())

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
print("\t--- Anesh Lab-1 ---")
# Step 1: Load the dataset
df = pd.read_csv('student_scores.csv')
print("\nInitial Data:\n", df.head())
# Step 2: Apply Min-Max normalization
scaler = MinMaxScaler()
df[['Math', 'Science', 'English']] = scaler.fit_transform(df[['Math', 'Science', 'English']])
print("\nNormalized Scores:\n", df.head())

import pandas as pd
print("\t--- Aneesh Lab-1 ---")
# Step 1: Load the dataset
df = pd.read_csv('customer_ages.csv')
print("\nInitial Data:\n", df.head())
# Step 2: Create bins and assign labels
bins = [18, 30, 50, 100]
labels = ['Young', 'Middle-aged', 'Senior']
df['AgeGroup'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False)
print("\nData after Binning:\n", df.head())
# Step 3: Calculate distribution of customers in each age group
age_group_distribution = df['AgeGroup'].value_counts()
print("\nAge Group Distribution:\n", age_group_distribution)

import pandas as pd
print("\t--- Aneesh Lab-1 ---")
# Step 1: Load the dataset
df = pd.read_csv('sales_data.csv')
print("\nInitial Data:\n", df.head())
# Step 2: Apply discretization
bins = [0, 5000, 20000, float('inf')]
labels = ['Low', 'Medium', 'High']
df['SalesCategory'] = pd.cut(df['Sales'], bins=bins, labels=labels)
print("\nData after Discretization:\n", df.head())
# Step 3: Analyze the distribution of sales categories
sales_category_distribution = df['SalesCategory'].value_counts()
print("\nSales Category Distribution:\n", sales_category_distribution)

import pandas as pd
from sklearn.feature_selection import SelectKBest, chi2
print("\t--- Mausam Lab-1 ---")
# Step 1: Load the dataset
df = pd.read_csv('medical_data.csv')
print("\nInitial Data:\n", df.head())
# Step 2: Define features and target variable
X = df.drop(columns=['Disease'])
y = df['Disease']
# Step 3: Apply Chi-square feature selection
selector = SelectKBest(score_func=chi2, k=3)
selector.fit(X, y)
# Step 4: Get the top 3 features
top_features = X.columns[selector.get_support()]
print("\nTop 3 Features for Predicting Disease:\n", top_features)